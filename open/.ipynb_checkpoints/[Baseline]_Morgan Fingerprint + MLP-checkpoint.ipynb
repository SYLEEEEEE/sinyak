{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ff09e1b",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import\" data-toc-modified-id=\"Import-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import</a></span></li><li><span><a href=\"#Pre-Processing\" data-toc-modified-id=\"Pre-Processing-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Pre-Processing</a></span></li><li><span><a href=\"#Custom-Dataset\" data-toc-modified-id=\"Custom-Dataset-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Custom Dataset</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Model</a></span></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Training</a></span></li><li><span><a href=\"#Inference\" data-toc-modified-id=\"Inference-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Inference</a></span></li><li><span><a href=\"#Submission\" data-toc-modified-id=\"Submission-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Submission</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pYzhJrEibIlq",
   "metadata": {
    "id": "pYzhJrEibIlq"
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f487ab4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T09:33:06.051739Z",
     "start_time": "2023-08-18T09:33:02.292033Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rdkit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrdkit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataStructs\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrdkit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mChem\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PandasTools, AllChem\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rdkit'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import PandasTools, AllChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714740f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T09:33:06.053677Z",
     "start_time": "2023-08-18T09:33:06.053670Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "seed_everything(42) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afd5126",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd052629",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T09:33:06.054272Z",
     "start_time": "2023-08-18T09:33:06.054266Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7KbqRv6I19Rg",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T09:33:06.055353Z",
     "start_time": "2023-08-18T09:33:06.055347Z"
    },
    "id": "7KbqRv6I19Rg"
   },
   "outputs": [],
   "source": [
    "PandasTools.AddMoleculeColumnToFrame(train,'SMILES','Molecule')\n",
    "PandasTools.AddMoleculeColumnToFrame(test,'SMILES','Molecule')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oXOFfJVW22DL",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T09:33:06.056096Z",
     "start_time": "2023-08-18T09:33:06.056090Z"
    },
    "id": "oXOFfJVW22DL"
   },
   "outputs": [],
   "source": [
    "def mol2fp(mol):\n",
    "    fp = AllChem.GetHashedMorganFingerprint(mol, 6, nBits=4096)\n",
    "    ar = np.zeros((1,), dtype=np.int8)\n",
    "    DataStructs.ConvertToNumpyArray(fp, ar)\n",
    "    return ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1MTlg0wx22DM",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T09:33:06.056973Z",
     "start_time": "2023-08-18T09:33:06.056964Z"
    },
    "id": "1MTlg0wx22DM"
   },
   "outputs": [],
   "source": [
    "# FPs column 추가\n",
    "train[\"FPs\"] = train.Molecule.apply(mol2fp)\n",
    "test[\"FPs\"] = test.Molecule.apply(mol2fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34a2ae9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T09:33:06.057719Z",
     "start_time": "2023-08-18T09:33:06.057713Z"
    }
   },
   "outputs": [],
   "source": [
    "# 사용할 column만 추출\n",
    "train = train[['FPs','MLM', 'HLM']]\n",
    "test = test[['FPs']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d289fc",
   "metadata": {},
   "source": [
    "## Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dade784e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T09:33:06.058601Z",
     "start_time": "2023-08-18T09:33:06.058591Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, target, transform, is_test=False):\n",
    "        self.df = df\n",
    "        self.target = target # HLM or MLM\n",
    "        self.is_test = is_test # train,valid / test\n",
    "\n",
    "        self.feature_select = transform\n",
    "        if not self.is_test: \n",
    "            self.fp = self.feature_select.fit_transform(np.stack(df['FPs']))\n",
    "        else: # valid or test\n",
    "            self.fp = self.feature_select.transform(np.stack(df['FPs']))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fp = self.fp[index]\n",
    "        if not self.is_test: # test가 아닌 경우(label 존재)\n",
    "            label = self.df[self.target][index]\n",
    "            return torch.tensor(fp).float(), torch.tensor(label).float().unsqueeze(dim=-1) # feature, label\n",
    "\n",
    "        else: # test인 경우\n",
    "            return torch.tensor(fp).float() # feature\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c600a122",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T09:33:06.059788Z",
     "start_time": "2023-08-18T09:33:06.059781Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = VarianceThreshold(threshold=0.05)\n",
    "\n",
    "train_MLM = CustomDataset(df=train, target='MLM', transform=transform, is_test=False)\n",
    "train_HLM = CustomDataset(df=train, target='HLM', transform=transform, is_test=False)\n",
    "\n",
    "input_size = train_MLM.fp.shape[1]\n",
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb36a46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T09:33:06.060548Z",
     "start_time": "2023-08-18T09:33:06.060541Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "CFG = {'BATCH_SIZE': 256,\n",
    "       'EPOCHS': 1000,\n",
    "       'INPUT_SIZE': input_size,\n",
    "       'HIDDEN_SIZE': 1024,\n",
    "       'OUTPUT_SIZE': 1,\n",
    "       'DROPOUT_RATE': 0.8,\n",
    "       'LEARNING_RATE': 0.001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090fa2f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T09:33:06.061393Z",
     "start_time": "2023-08-18T09:33:06.061387Z"
    }
   },
   "outputs": [],
   "source": [
    "# train,valid split\n",
    "train_MLM_dataset, valid_MLM_dataset = train_test_split(train_MLM, test_size=0.2, random_state=42)\n",
    "train_HLM_dataset, valid_HLM_dataset = train_test_split(train_HLM, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe86f36f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T09:33:06.062091Z",
     "start_time": "2023-08-18T09:33:06.062085Z"
    }
   },
   "outputs": [],
   "source": [
    "train_MLM_loader = DataLoader(dataset=train_MLM_dataset,\n",
    "                              batch_size=CFG['BATCH_SIZE'],\n",
    "                              shuffle=True)\n",
    "\n",
    "valid_MLM_loader = DataLoader(dataset=valid_MLM_dataset,\n",
    "                              batch_size=CFG['BATCH_SIZE'],\n",
    "                              shuffle=False)\n",
    "\n",
    "\n",
    "train_HLM_loader = DataLoader(dataset=train_HLM_dataset,\n",
    "                              batch_size=CFG['BATCH_SIZE'],\n",
    "                              shuffle=True)\n",
    "\n",
    "valid_HLM_loader = DataLoader(dataset=valid_HLM_dataset,\n",
    "                              batch_size=CFG['BATCH_SIZE'],\n",
    "                              shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8CHzFfvrbnOM",
   "metadata": {
    "id": "8CHzFfvrbnOM"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AWUlJIGf22DO",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T09:33:06.063218Z",
     "start_time": "2023-08-18T09:33:06.063212Z"
    },
    "id": "AWUlJIGf22DO"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_rate, out_size):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # fc 레이어 3개와 출력 레이어\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc_out = nn.Linear(hidden_size, out_size)\n",
    "        \n",
    "        # 정규화\n",
    "        self.ln1 = nn.LayerNorm(hidden_size)\n",
    "        self.ln2 = nn.LayerNorm(hidden_size)\n",
    "        self.ln3 = nn.LayerNorm(hidden_size)        \n",
    "        \n",
    "        # 활성화 함수\n",
    "        self.activation = nn.LeakyReLU()\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "     \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.ln1(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = self.fc2(out)\n",
    "        out = self.ln2(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = self.fc3(out)\n",
    "        out = self.ln3(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = self.fc_out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9IlcjfOB22DO",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T09:33:06.064064Z",
     "start_time": "2023-08-18T09:33:06.064059Z"
    },
    "id": "9IlcjfOB22DO"
   },
   "outputs": [],
   "source": [
    "model_MLM = Net(CFG['INPUT_SIZE'],CFG['HIDDEN_SIZE'],CFG['DROPOUT_RATE'],CFG['OUTPUT_SIZE'])\n",
    "model_HLM = Net(CFG['INPUT_SIZE'],CFG['HIDDEN_SIZE'],CFG['DROPOUT_RATE'],CFG['OUTPUT_SIZE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IuQe4Za322DP",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T09:33:06.064792Z",
     "start_time": "2023-08-18T09:33:06.064787Z"
    },
    "id": "IuQe4Za322DP"
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer_MLM = torch.optim.Adam(model_MLM.parameters(), lr=CFG['LEARNING_RATE'])\n",
    "optimizer_HLM = torch.optim.Adam(model_HLM.parameters(), lr=CFG['LEARNING_RATE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e032e346",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210fa6e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T09:33:06.065313Z",
     "start_time": "2023-08-18T09:33:06.065308Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(train_loader, valid_loader, model, criterion, optimizer, epochs):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(inputs)\n",
    "            loss = criterion(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            valid_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for inputs, targets in valid_loader:\n",
    "                    output = model(inputs)\n",
    "                    loss = criterion(output, targets)\n",
    "                    valid_loss += loss.item()\n",
    "                    \n",
    "            print(f'Epoch: {epoch}/{epochs}, Train Loss: {running_loss/len(train_loader)}, Valid Loss: {valid_loss/len(valid_HLM_loader)}')\n",
    "            \n",
    "            model.train()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda577c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T09:33:06.066041Z",
     "start_time": "2023-08-18T09:33:06.066036Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Training Start: MLM\")\n",
    "model_MLM = train(train_MLM_loader, valid_MLM_loader, model_MLM, criterion, optimizer_MLM, epochs=CFG['EPOCHS'])\n",
    "\n",
    "print(\"Training Start: HLM\")\n",
    "model_HLM = train(train_HLM_loader, valid_HLM_loader, model_HLM, criterion, optimizer_HLM, epochs=CFG['EPOCHS'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39bbce5",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbc3181",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T09:33:06.066623Z",
     "start_time": "2023-08-18T09:33:06.066618Z"
    }
   },
   "outputs": [],
   "source": [
    "test_MLM = CustomDataset(df=test, target=None, transform=transform, is_test=True)\n",
    "test_HLM = CustomDataset(df=test, target=None, transform=transform, is_test=True)\n",
    "\n",
    "test_MLM_loader = DataLoader(dataset=test_MLM,\n",
    "                             batch_size=CFG['BATCH_SIZE'],\n",
    "                             shuffle=False)\n",
    "\n",
    "test_HLM_loader = DataLoader(dataset=test_HLM,\n",
    "                             batch_size=CFG['BATCH_SIZE'],\n",
    "                             shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d8a4e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T09:33:06.067631Z",
     "start_time": "2023-08-18T09:33:06.067626Z"
    }
   },
   "outputs": [],
   "source": [
    "def inference(test_loader, model):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs in test_loader:\n",
    "            output = model(inputs)\n",
    "            preds.extend(output.cpu().numpy().flatten().tolist())\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9794de7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T09:33:06.068489Z",
     "start_time": "2023-08-18T09:33:06.068483Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions_MLM = inference(test_MLM_loader, model_MLM)\n",
    "predictions_HLM = inference(test_HLM_loader, model_HLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb42d64",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e574c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T09:33:06.069395Z",
     "start_time": "2023-08-18T09:33:06.069389Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./sample_submission.csv')\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569d8575",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T09:33:06.069852Z",
     "start_time": "2023-08-18T09:33:06.069847Z"
    }
   },
   "outputs": [],
   "source": [
    "submission['MLM'] = predictions_MLM\n",
    "submission['HLM'] = predictions_HLM\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaf46fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T09:33:06.070369Z",
     "start_time": "2023-08-18T09:33:06.070364Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv('baseline_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "804.705872px",
    "left": "213px",
    "top": "118.698524px",
    "width": "211.985291px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "88a5da79f9030d36a713e3ceec9ed9a47a216907c035af9944c458137c4e5cb3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
